---
permalink: /
title: ""
excerpt: "PhD student at Tulane University"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<p style="text-align: justify;">
<br><br>
I completed my Ph.D. in Computer Science from Tulane University in 2024, under the guidance of <a href ="http://www.cs.tulane.edu/~jhamm3/"> Prof. Jihun Hamm</a>. 
The primary thrusts of my research are summarized as follows. The first aspect of my research focuses on rigorously analyzing how different performance metrics (such as accuracy, adversarial robustness, and transferability to downstream tasks) are affected when training and test distributions differ. The second aspect concentrates on developing algorithms inspired by these theoretical insights to improve the performance of the ML models under distribution shifts. Overall, my research analyzes the success of learning models in in-domain in-task and cross-domain cross-task settings and analyzes the impact of distribution shifts in these settings. 
</p>

Research Interest
======
<p style="text-align: justify;">
To deepen the understanding of machine learning models' robustness to different distribution shifts such as shifts induced by corrupted data, shifts induced by adversarial attacks, etc..
</p>

Publications
======
* “[Understanding the Transferability of Representations via Task-Relatedness](https://arxiv.org/abs/2307.00823)”.
  <br> [Code](https://github.com/akshaymehra24/TaskTransferAnalysis) [Poster](http://akshaymehra24.github.io/files/Neurips_poster.pdf)
  <br> <b>Akshay Mehra</b>, Yunbei Zhang, and Jihun Hamm.
  <br><i>Neural Information Processing Systems (NeurIPS) 2024.</i>
* “[OT-VP: Optimal Transport-guided Visual Prompting for Test-Time Adaptation](https://arxiv.org/abs/2407.09498)”.
  <br> Yunbei Zhang, <b>Akshay Mehra</b>, and Jihun Hamm.
  <br><i>Winter Conference on Applications of Computer Vision (WACV) 2025. </i>
* “[Test-time Assessment of a Model's Performance on Unseen Domains via Optimal Transport](https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/papers/Mehra_Test-time_Assessment_of_a_Models_Performance_on_Unseen_Domains_via_CVPRW_2024_paper.pdf)”.
  <br> [Code](https://github.com/akshaymehra24/TETOT) [Poster](http://akshaymehra24.github.io/files/TCV_poster.pdf)
  <br> <b>Akshay Mehra</b>, Yunbei Zhang, and Jihun Hamm.
  <br><i>Computer Vision and Pattern Recognition (CVPR) Workshop on Fair, Data-efficient, and Trusted Computer Vision 2024. </i>
* “[On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization](https://openaccess.thecvf.com/content/WACV2024/papers/Mehra_On_the_Fly_Neural_Style_Smoothing_for_Risk-Averse_Domain_Generalization_WACV_2024_paper.pdf)”.
  <br> [Code](https://github.com/akshaymehra24/RiskAverseDG) [Poster](http://akshaymehra24.github.io/files/wacv24-252.pdf)
  <br> <b>Akshay Mehra</b>, Yunbei Zhang, Bhavya Kailkhura, and Jihun Hamm.
  <br><i>Winter Conference on Applications of Computer Vision (WACV) 2024. </i>
* “[A Spectral View of Randomized Smoothing under Common Corruptions: Benchmarking and Improving Certified Robustness](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640645.pdf)”. 
  <br> Jiachen Sun, <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen, Dan Hendrycks, Jihun Hamm and Z. Morley Mao.
  <br><i>European Conference on Computer Vision (ECCV) 2022. </i>
* “[Understanding the Limits of Unsupervised Domain Adaptation via Data Poisoning](https://papers.nips.cc/paper/2021/file/90cc440b1b8caa520c562ac4e4bbcb51-Paper.pdf)”. 
  <br> [Code](https://github.com/akshaymehra24/LimitsOfUDA), [Poster](http://akshaymehra24.github.io/files/Neurips_2021_poster.pdf)
  <br> <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm. 
  <br> <i>Neural Information Processing Systems (NeurIPS) 2021.</i>
* “[How Robust are Randomized Smoothing based Defenses to Data Poisoning?](https://openaccess.thecvf.com/content/CVPR2021/html/Mehra_How_Robust_Are_Randomized_Smoothing_Based_Defenses_to_Data_Poisoning_CVPR_2021_paper.html)”. 
  <br> [Code](https://github.com/akshaymehra24/poisoning_certified_defenses), [Poster](http://akshaymehra24.github.io/files/cvpr21_poster.pdf)
  <br> <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm. 
  <br> <i>Computer Vision and Pattern Recognition (CVPR) 2021. </i>
* “[Penalty Method for Inversion-Free Deep Bilevel Optimization](https://proceedings.mlr.press/v157/mehra21a/mehra21a.pdf)”. 
  <br> [Code](https://github.com/jihunhamm/bilevel-penalty), [Poster](http://akshaymehra24.github.io/files/acml21_poster.pdf)
  <br> <b>Akshay Mehra</b>, Jihun Hamm. 
  <br> <i>Asian Conference on Machine Learning (ACML) 2021.</i>

Preprints
======
* “[Model-agnostic Coreset Selection via LLM-based Concept Bottlenecks](https://arxiv.org/abs/2502.16733)”. 
  <br> <b>Akshay Mehra</b>, Trisha Mittal, Subhadra Gopalakrishnan, Joshua Kimball.
* “[Understanding the Robustness of Multi-Exit Models under Common Corruptions](https://arxiv.org/abs/2212.01562)”. 
  <br> <b>Akshay Mehra</b>, Skyler Seto, Navdeep Jaitly and Barry-John Theobald
* “[Do Domain Generalization Methods Generalize Well?](https://openreview.net/pdf?id=SRWIQ0Yl53m)”. 
  <br> [Code](https://github.com/akshaymehra24/LimitsOfDG), [Poster](http://akshaymehra24.github.io/files/ml_safety_poster.pdf)
  <br> <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm. 
  <br><i>Workshop on Machine Learning Safety at Neural Information Processing Systems (NeurIPS) 2022.</i>
* “[Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples](https://arxiv.org/abs/1711.04368)”.
  <br> Jihun Hamm and <b>Akshay Mehra</b>. 
